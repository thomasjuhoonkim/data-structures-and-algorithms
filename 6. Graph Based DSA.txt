Graph Data Structure:
    https://www.programiz.com/dsa/graph
    - A graph data structure is a collection of nodes that have data
      and are connected to other nodes.
    Example:
        - On facebook, everything is a node.
        - That includes User, Photo, Album, Group, Page, Comment
          Story, Video, Link, Note... anything that has data is a node.
        - Every relationship is an ede from one node to another.
        - Whether you post a photo, join a group, like a page, etc.
        - A new edge is created for that relationship.
        - All of facebook is then a collection of these nodes and edges.
        - This is because facebook uses a graph data structure to store its data.
    
    More precisely, a graph is a data structure(V, E) that consists of:
        - A collection of vertices V
        - A collection of edges E, represented as ordered pairs of vertices (u,v)
        In the graph:
            V = {0, 1, 2, 3}
            E = {(0,1), (0,2), (0,3), (1,2)}
            G = {V, E}
    
    Graph Terminology:
        Adjacency:
            - A vertex is said to be adjacent to another vertex if there is an edge connecting them.
            - Vertices 2 and 3 arenot adjecent because there is no edge between them.
        Path:
            - A sequence of edges that allows you to go from vertex A to vertex V is called a path.
            - 0-1, 1-2 and 0-2 are paths from vertex 0 to vertex 2.
        Directed Graph:
            - A graph is which an edge (u,v) doesn't necessarily mean that there is an edge (v, u) as well.
            - The edges in such a graph are represented by arrows to sohw the direction of the edge.
        
    Graph Representation:
        - Graphs are commonly represented in two ways:
        1. Adjacency Matrix:
            - An adjacency matrix is a 2D array of V x V vertices.
            - Each row and column represent a vertex.
            - If the value of any element a[i][j] is 1, it represents that there is an edge connecting vertex i and vertex j.
            # Flashbacks to linear algebra graphs
            - Since it is an undirected graph, for edge (0,2),
              we also need to mark edge (2,0); making the adjacency matrix symmetric about the diagonal.
            - Edge lookup (checking if an edge exists between vertex A and vertex B) is extremely fast in adjacency matrix
              representation but we have to reserve space for every possible link between all vertices (V x V),
              so it requires more space.
        
        2. Adjacency List
            - An adjacency list represents a graph as an array of linked lists.
            - The index of the array represents a vertex and each element in its linked list represents other vertices
              that form an edge with the vertex.
            The adjacency list for the graph we made in the first example is as follows:
            - An adjacency list is efficient in terms of storage because we only need to store the values for the edges.
            - For a graph with millions of vertices, this can mean a lot of saved space.
    
    Graph Operations:
        - Check if the element is present in the graph
        - Graph Traversal
        - Add elements(vertex, edges) to graph
        - Finding the path from one vertex to another

=================================================================================================================================

Spanning Tree and Minimum Spanning Tree:
    https://www.programiz.com/dsa/spanning-tree-and-minimum-spanning-tree
    - Before we learn about spanning trees, we need to understand two graphs:
        - Undirected graphs
        - Connected graphs
    - An undirected graph is a graph in which the edges do not point in any direction (ie. the edges are bidirectional)
    - A connected graph is a graph in which there is always a path from a vertex to any other vertex.

    Spanning Tree:
        - A spanning tree is a sub-graph of an undirected connected graph,
          which includes all the vertices of the graph with a minimum possible number of edges.
        - If a vertex is missed, then it is not a spanning tree.
        - The edges may or may not have weights assigned to them.
        [The total number of spanning trees with n vertices that can be created from a complete graph is equal to n^(n-2)]
        - If we have n = 4, the maximum number of possible spanning trees is equa to 4^(4-2)=16.
        - Thus, 16 spanning trees can be formed from a complete graph with 4 vertices.
        Example of a Spanning Tree: check website

    Minimum of a Spanning Tree:
        - A minimum spanning tree is a spanning tree in which the sum of the weight of the edges is as minimum as possible.
        Example of a minimum Spanning Tree: check website
        - The minimum spanning tree from a graph is found using the following algorithms:
            1. Prim's Algorithm
            2. Kruskal's Algorithm
    
    Spanning Tree Applications:
        - Computer Network Routing Protocol
        - Cluster Analysis
        - Civil Network Planning
    
    Minimium Spanning Tree Applications:
        - To find paths in the map
        - To design networks like telecommunications networks, water supply networks, and electrical grids.
        
=========================================================================================================================

Strongly Connected Components:
    https://www.programiz.com/dsa/strongly-connected-components
    - A strongly connected component is the portion of a directed graph in which there is a path from
      each vertex to another vertex.
    - It is applicable only on a directed graph
    - Strongly connected components are sections of the graph where every vertex has an edge to eachother
    - Usually triangles, squares, stars, etc.
    - These are also rotating clockwise or anticlockwise
    - These components can be found using Kosaraju's Algorithm

    Kosaraju's Algorithm:
        - Kosaraju's Algorithm is based on the depth-first search algorithm implemented twice.
        Three steps are involved:
            1. Perform a depth first search on the whole graph
                - Let us start from vertex-0, visit all of its child vertices, and mark the visited vertices as done.
                - If a vertex leads to an already visited vertex, then push this vertex to the stack.
                - For example:
                    - Starting from vertex-0, go to vertex-1, vertex-2, and then to vertex-3.
                    - Vertex-3 leads to already visited vertex-0, so push the source vertex (ie. vertex-3)
                      into the stack.

                    - Go to the previous vertex (vertex-2) and visit its child vertices ie. vertex-4, vertex-5, vertex-6, and vertex-7 sequentially.
                      Since there is nowhere to go from vertex-7, push it into the stack.
                    
                    - Go to the previous vertex (vertex-6), and visit its child vertices. But, all of its child vertices are visited,
                      so push it to the stack.
                    
                    - Similarly, a final stack is created.
            
            2. Reverse the original graph.
            3. Perform depth-first search on the reversed graph.
                - Start from the top vertex of the stack. Traverse through all of its child vertices.
                - Once the already visited vertex is reached, one strongly connected component is formed.
                For example:
                    - Pop vertex-0 from the stack.
                    - Starting from vertex-0, traverse through its child vertices (vertex-0, vertex-1, vertex-2, vertex-3 in sequence)
                      and mark them as visited.
                    - The child of vertex-3 is already visited, so these visited vertices form one strongly connected component.

                    - Go to the stack and pop the top vertex if already visited.
                    - Otherwise, choose the top vertex from the stack and traverse through its child vertices as presented above.
            
            4. Thus, the strongly connected components are: Square, Triangle, single vertex
    
    Kosaraju's Algorithm Complexity:
        - Kosaraju's algorithm runs in linear time i.e O(V+E)
    
    Strongly Connected Components Applications:
        - Vehicle routing applications
        - Maps
        - Model-checking in formal verification

=====================================================================================================================================

Adjacency Matrix:
    - An adjacency matrix is a way of representing a graph as a matrix of booleans (0's and 1's).
    - A finite graph can be represented as the form of a square matrix on a computer,
      where the boolean value of the matrix indicates if there is a direct path between two vertices.
    For example:
        - Header row and columns are all vertices on graph
          0 1 2 3
        0 0 1 1 1
        1 1 0 1 0
        2 1 1 0 0
        3 1 0 0 0

        - Each cell in the above table/matrix is represented as Aij, where i and j are vertices.
        - The value of Aij is either 1 or 0 depending on whether there is an edge from vertex i
          to vertex j
        - If there is a path from i to j, then the value of Aij is 1 otherwise it's 0.
        - For instance, there is a path from vertex 1 to vertex 2, so A12 is 1 and there is no
          path from vertex 1 to 3, so A13 is 0.
        - In case of undirected graphs, the matrix is symmetrix about the diagonal because
          of every edge (i, j).
    
    Pros of Adjacency Matrix:
        - The basic operations like adding an edge, removing an edge, and checking whether
          there is an edge from vertex i to vertex j are extremely time efficient,
          constant time operations.
        - If the graph is dense and the number of edges is large, an adjacency matrix should
          be the first choice. Even if the graph and the adhacency matrix is sparse, we can
          represent it using data structures for sparse matrices.
        - The biggest advantage, however, comes from the use of matrices. The recent advances in
          hardware enable us to perform even expensive matrix operations on the GPU.
        - By performing operations on the adjacent matrix, we can get important insights
          into the nature of the graph and the relationship between its vertices.
    
    Cons of Adjacency Matrix:
        - The VxV space requirement of the adjacency matrix makes it a memory hog.
          Graphs out in the wild usually don't have too many connections and this is the major
          reason why adjacency lists are the better choice for most tasks.
        - While basic operations are easy, operations like inEdges and outEdges are expensive
          when using the adjacency matrix representation.
        
    Adjacency Matrix Applications:
        - Creating routing table in networks
        - Navigation tasks

=====================================================================================================

Adjacency List:
	https://www.programiz.com/dsa/graph-adjacency-list
	- An adjacency list represents a graph as an array of linked lists.
	- The index of the array represents a vertex and each element in its linked list represents
	  the other vertices that form an edge with the vertex.
	Example:
		0->1->2->3
		1->0->2
		2->0->1
		3->0
		- Here 0, 1, 2, 3 are vertices and each of them forms a linked list with all of its
		  adjacency vertices. For instance, vertex 1 jas two adjacent vertices 0 and 2.
		- Therefore, 1 is linked with 0 and 2.
	
	Pros of Adjacency List:
		- An adjacency list is efficient in terms of storage because we only need to store the
		  values for the edges.
		- For a sparse graph with millions of vertices and edges, this can mean a lot of saved space.
		- It also helps to find all the vertices adjacent to vertex easily.

	Cons of Adjacency List:
		- Finding the adjacent list is not quicker than adjacency matrix because all
		  the connected nodes must be first explored to find them.
	
	Adjacency List Structure:
		- The simplest adjacency list needs a node data structure to store a vertex and a graph
		  data structure to oragnize the nodes.
		- We stay close to the basic definition of a graph - a collection of vertices and edges
		  {V, E}.
		- For simplicity, we use an unlabeled graph as opposed to a labeled one
		  ie. the vertices are identified by their indices 0,1,2,3
		
		struct node{
			int vertex;
			struct node* next;
		};

		struct Graph{
			int numVertices;
			struct node** adjLists;
		};

		- Don't let the struct node** adjLists overwhelm you.
		- All we are saying is we want to store a pointer to struct node*.
		- This is because we don't know how many vertices the graph will have and so we
		  cannot create an array of Linked Lists at compile time.
	
	Adjacency List C++:
		- It is the same structure but by using the in-built list STL data structures of C++,
		  we make the structure a bit cleaner. We are also able to abstract the details
		  of the implementation.

		class Graph{
			int numVertices;
			list<int> *adjLists;
			
		public:
			Graph(int V);
			void addEdge(int src, int dest);
		};

	Adjacency List Python:
	- There is a reason Python gets so much love.
	- A simple dictionary of vertices and its edges is a sufficient represntation of a graph.
	- you can make the vertex itself as complex as you want.
		graph = {'A': set(['B', 'C']),
				 'B': set(['A', 'D', 'E']),
				 'C': set(['A', 'F']),
				 'D': set(['B']),
				 'E': set(['B', 'F']),
				 'F': set(['C', 'E'])}
	
	Applications of Adjacency List:
		- It is faster to use adjacency lists for graphs having less number of edges.

===================================================================================================

Depth First Search (DFS):
	https://www.programiz.com/dsa/graph-dfs
	- Depth first Search or Depth first traversal is a recursive algorithm for searching all
	  the vertices of a graph or tree data structure.
	- Traversal means visiting all the nodes of a graph.
	
	Depth First Search Algorithm:
		- A standard DFS impementation pyts each vertex of the graph into one of two categories:
		1. Visitied
		2. Not Visitied
		- The purpose of the algorithm is to mark each vertex as visited while avoiding cycles.
		The DFS algorithm works as follows:
			1. Start by putting any one of the graph's vertices on top of the stack.
			2. Take the top item of the stack and add it to the visited list.
			3. Create a list of that vertex's adjacent nodes. Add the ones which aren't in
			   the visited list to the top of the stack.
			4. Keep reapting steps 2 and 3 until the stack is empty.
	
	Depth First Search Example: check website

	DFS Pseodocode (recursive implementation):
		- The pseudocode for DFS is shown below. In the init() function,
		  notice that we run the DFS function on every node.
		- This is because the graph might have two different disconnected parts so to make ssure
		  that we cover every vertex, we can alsp run the DFS algorithm on every node.
		
		DFS(G, u)
			u.visited = true
			for each v ∈ G.Adj[u]
				if v.visited == false
					DFS(G,v)
			
		init() {
			For each u ∈ G
				u.visited = false
			For each u ∈ G
			DFS(G, u)
		}

	DFS Implementation in Python, Java and C/C++: check implementation examples

	Complexity of Depth First Search:
		- The time complexity of the DFS algorithm is represented in the form of O(V +E),
		  where V is the number of nodes and E is the number of edges.
		- The space complexity of the algorithm is O(V).
	
	Applications of DFS Algorithm:
		1. For finding the path
		2. To test if the graph is bipartite
		3. For finding he strongly connected components of a graph
		4. For detecting cycles in a graph

====================================================================================================

Breadth First Search:
	https://www.programiz.com/dsa/graph-bfs
	- Traversal means visiting all the nodes of a graph.
	- Breadth First Traversal or Breadth First Search is a recursive algorithm for searching
	  all the vertices of a graph or tree data structure.
	BFS Algorithm:
		- A standard BFS implementation puts each vertex of the graph into one of two categories.
		1. Visited
		2. Not Visited
		- The purpose of the algorithm is to mark each vertex as visited while avoiding cycles.
		Algorithm:
			1. Start by putting any one of the graph's vertices at the back of a queue.
			2. Take the front item of the queue and add it to the visited list.
			3. Create a list of that vertex's adjacent nodes. Add the noes which aren't in the
			   visited list to the back of the queue.
			4. Keep repeating steps 2 and 3 until the queue is empty.
		- The graph might have two different disconnected parts so to make sure that we cover
		  every vertex, we can also run the BFS algorithm on every node.
	
	BFS Example: check website

	BFS pseudocode:
		create a queue Q 
		mark v as visited and put v into Q 
		while Q is non-empty 
			remove the head u of Q 
			mark and enqueue all (unvisited) neighbours of u
	
	BFS implementation example: check implementation files

	BFS Algorithm Complexity:
		- The time complexity of the BFS algorithm is represented in the form of O(V + E),
		  where V is the number of nodes and E is the number of edges.
		- The space complexity of the algorithm is O(V).
	
	BFS Algorithm Applciations:
		1. To build index by search index.
		2. For GPS Navigation
		3. Path finding algorithms
		4. In Ford-Fulkerson algorithm to find maximum flow in a network
		5. Cycle deteciton in an undirected graph
		6. In minimum spanning tree.

===============================================================================================

Bellman Ford's Algorithm:
	https://www.programiz.com/dsa/bellman-ford-algorithm
	- Bellman Ford Algorithm helps is find the shortest path from a vertex to all other vertices
	  of a weighted graph.
	- It is similar to Dijkstra's algorithm but it can work with graphs in which edges can have
	  negative weights.
	
	Why would one ever have edges with negative weights in real life?
		- Negative weight edges might seem useless at first but they can explain a lot of
		  phenomena like cashflow, the heat released/absolred in a chemical reaction, etc.
		- For instance if there are different ways to reach from one chemical A to another chemical B 
		  each method with have sub-reactions involving both heat dissipation and absorption.
		- If we want to find the set of reacitons where minimum energy is required, then we will
		  need to be able to factor in the heat absorption as negative weights and heat dissipation
		  as positive weights.
	
	Why do we need to be careful with negative weights?
		- Negative weight edges can create negative weight cycles ie. a cycle that will reduce the
		  total path distance by coming back to the same point.
		- Shortest path algorithms like Dijkstra's Algorithm that aren't able to detect such a
		  cycle can give an incorrect result because they can go through a negative weight cycle
		  and reduce the path length.
	
	How Bellman Ford's algorithm works:
		- Bellman Ford algorithm works by overestimating the length of the path from the starting 
		  vertex to all other vertices. Then it iteratively relaxes those estimates by finding new
		  paths taht are shorter than the previously overestimated paths.
		- By doing this repeatedly for all vertices, we can guarantee that the result is optimized.
	
	Bellman Ford Pseudocode:
		- We need to maintain the path distance of every vertex.
		- We can store that in an array of size v, where v is the number of vertices.
		- We also want to be able to get the shortest path, not only know the legnth of the
		  shortest path.
		- For this, we map each vertex to the vertex that last updated its path length.
		- Once the algorithm is over, we can backtrack from the destination vertex to the source
		  vertex to find the path.

		function bellmanFord(G, S)
			for each vertex V in G
				distance[V] <- infinite
				previous[V] <- NULL
			distance[S] <- 0

			for each vertex V in G				
				for each edge (U,V) in G
				tempDistance <- distance[U] + edge_weight(U, V)
				if tempDistance < distance[V]
					distance[V] <- tempDistance
					previous[V] <- U

			for each edge (U,V) in G
				If distance[U] + edge_weight(U, V) < distance[V}
				Error: Negative Cycle Exists

			return distance[], previous[]
		
	Bellman Ford vs Dijkstra:
		- Bellman Ford's algorithm and Dijkstra's algorithm are very similar in structure.
		  While Dijkstra looks only to the immediate neighbors of a vertex, Bellman goes through
		  each edge in every iteraiton.
	
	Bellman Ford Algorithm Implementation Example: check files

	Bellman Ford's Complexity:
		Time Complexity:
			Best Case Complexity: O(E)
			Average Case Complxity: O(VE)
			Worst Case Complexity: O(VE)
		Space Complexity: O(V)
	
	Bellman Ford's Algorithm Applications:
		1. For calculating shortest paths in routing algorithms
		2. For finding the shortest path